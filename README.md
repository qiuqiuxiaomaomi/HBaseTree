# HBaseTree
HBase 技术研究

![](https://i.imgur.com/XKgWQsD.png)

![](https://i.imgur.com/9JukYh2.jpg)

<pre>
列式存储数据库以列为单位聚合数据，然后将列值顺序的存入磁盘，这种存储方法不同于行式存储的传统数据库库，行式存储数据库连续的
存储整行。

列式存储的出现主要基于这样一种假设：对于特定的查询，不是所有的值都是必须的，尤其是在分析型数据库里，这种情况很常见。

在这种设计中，减少I/O只是众多主要因素之一，它还有其它的优点：
    因为列的数据类型天生是相似的，即便逻辑上每一行之间有轻微的不同，但仍旧比按行存储的结构聚集在一起的数据更利于压缩，因为大多数的压缩只关注有限的压缩窗口
</pre>

![](https://i.imgur.com/N4Q4UaC.jpg)

<pre>
一行由若干列组成，若干列又构成一个列族，一个列族的所有列存储在同一个底层的存储文件里，这个列族文件叫做HFile

列族需要在表创建时就定义好，并且不能修改得太频繁，数量也不能太多。

常见的引用列的格式为  family:qualifier，列族的数量最多只限于几十，实际更小，然而一个列族中的列的数量没有限制。

HBase是按照BigTable模型实现的，是一个稀疏的，分布式的，持久化的，多维的映射，由行键，列键，时间戳索引。

存储文件通常保存在hadoop分布式文件系统HDFS中，HDFS提供一个可扩展的，持久的，冗余的HBase存储层。存储文件通过将更改写入到可配置数目的物理服务器中，以保证数据不丢失。

每次更新数据时，都会先将数据记录在（commit log）提交日志中，在HBase中这叫做预写日志（write-ahead log, WAL），然后才会将这些数据写入内存中的
memstore中，一旦内存保存的写入数据的累积超过一个给定的最大值，系统就会将这些数据移出内存作为HFile文件刷写到磁盘中，数据移出内存之后，系统就会
丢弃对应的提交日志，只保留未持久化到磁盘中的提交日志，在系统将数据移出memstore写入磁盘的过程中，可以不必阻塞系统的读写，通过滚动内存中的memstore
就可以达到这个目的，即用空的新的memstore获取更新数据，将满的旧的memstore转换成一个文件。
</pre>

<pre>
HBase自动分区
    HBase中扩展和负载均衡的基本单元称为region，region本质上是以行键排序的连续存储的区间，如果region太大，系统就会把它们动态拆分，相反地，就把多个region合并，以减少存储文件数量。

HBase是一个分布式的，持久的，强一致性的存储系统，具有近似最优的写性能和出色的读性能，它充分利用了磁盘空间，支持特定列族切换可压缩算法。
HBase继承自BigTable模型，只考虑单一的索引，类似于RDBMS中的主键，提供了服务器端钩子，可以实施灵活的辅助索引解决方案，此外，它还提供了过滤器功能，减少了网络传输的数据量。
HBase并未将说明性查询语言作为核心实现的一部分，对事务的支持也有限，但行原子性和“读-修改-写”操作在实践中弥补了这个缺陷，它们覆盖了大部分的使用场景并消除了在其它系统中经历过的死锁，等待等问题。
HBase在进行负载均衡和故障恢复时对客户端是透明的，在生产系统中，系统的可扩展性体现在系统自动 伸缩的过程中，更改集群并不涉及重新全量负载均衡和数据重分区，但整个处理过程完全是自动化的。
</pre>

<pre>
下载安装
    下载HBase，解压，配置conf/hbase-site.xml， 配置数据目录， 启动， bin/start-hbase.sh, 进入 bin/hbase shell, status， 查询hbase运行状态
</pre>

<pre>
在实践中，为了能够像MapReduce一样有效的利用你HDFS, HBASE大多始于Hadoop安装在一起的，这样能够很大程度上减少对网络I/O的需求，同时能够加快处理速度，当在同一个服务器上运行Hadoop和HBase时，
最少会有三个进程((DataNode, TaskTracker, RegionServer)

服务器
    在HBase和Hadoop中有两种类型的机器:
	     Master（HDFS的NameNode, MapReduce的jobtracker, 以及HBase的Master）
		 Slave(HDFS的DataNode, MapReduce的tasktracker， 以及HBase的RegionServer)

CPU
   使用单核CPU机器，同时运行3个或者更多的Java进程和操作系统的服务进程是不合理的，在生产系统中，通常采用的是多核处理器。四核的处理器能够满足需求。
</pre>

![](https://i.imgur.com/t9rmxAX.jpg)

<pre>
磁盘
    数据存储在slave机器上，因此slave机器需要大量的存储空间，用户需要根据主要是面向读写，还是数据加工，来平衡可用的CPU内核数量与磁盘数量的使用。通常应该
	保证每个磁盘至少一个核，所以在8核心服务器增加6块磁盘是较优的，加入更多磁盘可能并不会带来显著的性能提升。
	磁盘模式： JBOD模式
	          RAID模式
	一般推荐使用SATA盘，因为SATA比SAS更节省成本，虽然SAS安全性比SATA高，但是一半的软件策略中是跨机架数据冗余，因此可以放心的使用SATA盘，虽然3.5英寸的磁盘比2.5英寸的磁盘可靠，但考虑到服务器机架的因素，可以选择2.5寸的磁盘。
</pre>

<pre>
Hadoop
    目前HBase只能依赖特定的Hadoop版本，其中的主要原因之一是HBase与Hadoop之间的远程调用API，RPC协议是版本华的，并且需要调用方与被调用方相互匹配，细微的差异就可能导致通信失败。
</pre>

<pre>
HBase是生产中使用最广泛的且进过检验的文件系统，几乎所有的生产集群都是用HDFS作为底层存储层，它被证明是稳定可靠的系统，然而不适用HDFS可能会产生不可控的风险和一些后续的问题。
HDFS如此受欢迎的主要原因是，它的机制包含了冗余，容错性和可扩展性。无论选择哪个文件系统都应该提供类似的保障，因为HBASE需要嘉定文件系统的数据存储是可靠度额，并且HBASE本身没有办法复制
数据并维护自身存储文件袋额副本，因此较低层次的文件系统必须提供此功能
</pre>

![](https://i.imgur.com/CmThJmL.jpg)

<pre>
本地模式
    本地文件系统实际上完全绕过了Hadoop，即不使用HDFS或任何其他集群，HBase使用FileSystem类连接到文件系统实现。
</pre>