# HBaseTree
HBase 技术研究

![](https://i.imgur.com/XKgWQsD.png)

![](https://i.imgur.com/9JukYh2.jpg)

<pre>
列式存储数据库以列为单位聚合数据，然后将列值顺序的存入磁盘，这种存储方法不同于行式存储的传统数据库库，行式存储数据库连续的
存储整行。

列式存储的出现主要基于这样一种假设：对于特定的查询，不是所有的值都是必须的，尤其是在分析型数据库里，这种情况很常见。

在这种设计中，减少I/O只是众多主要因素之一，它还有其它的优点：
    因为列的数据类型天生是相似的，即便逻辑上每一行之间有轻微的不同，但仍旧比按行存储的结构聚集在一起的数据更利于压缩，因为大多数的压缩只关注有限的压缩窗口
</pre>

![](https://i.imgur.com/N4Q4UaC.jpg)

<pre>
一行由若干列组成，若干列又构成一个列族，一个列族的所有列存储在同一个底层的存储文件里，这个列族文件叫做HFile

列族需要在表创建时就定义好，并且不能修改得太频繁，数量也不能太多。

常见的引用列的格式为  family:qualifier，列族的数量最多只限于几十，实际更小，然而一个列族中的列的数量没有限制。

HBase是按照BigTable模型实现的，是一个稀疏的，分布式的，持久化的，多维的映射，由行键，列键，时间戳索引。

存储文件通常保存在hadoop分布式文件系统HDFS中，HDFS提供一个可扩展的，持久的，冗余的HBase存储层。存储文件通过将更改写入到可配置数目的物理服务器中，以保证数据不丢失。

每次更新数据时，都会先将数据记录在（commit log）提交日志中，在HBase中这叫做预写日志（write-ahead log, WAL），然后才会将这些数据写入内存中的
memstore中，一旦内存保存的写入数据的累积超过一个给定的最大值，系统就会将这些数据移出内存作为HFile文件刷写到磁盘中，数据移出内存之后，系统就会
丢弃对应的提交日志，只保留未持久化到磁盘中的提交日志，在系统将数据移出memstore写入磁盘的过程中，可以不必阻塞系统的读写，通过滚动内存中的memstore
就可以达到这个目的，即用空的新的memstore获取更新数据，将满的旧的memstore转换成一个文件。
</pre>

<pre>
HBase自动分区
    HBase中扩展和负载均衡的基本单元称为region，region本质上是以行键排序的连续存储的区间，如果region太大，系统就会把它们动态拆分，相反地，就把多个region合并，以减少存储文件数量。

HBase是一个分布式的，持久的，强一致性的存储系统，具有近似最优的写性能和出色的读性能，它充分利用了磁盘空间，支持特定列族切换可压缩算法。
HBase继承自BigTable模型，只考虑单一的索引，类似于RDBMS中的主键，提供了服务器端钩子，可以实施灵活的辅助索引解决方案，此外，它还提供了过滤器功能，减少了网络传输的数据量。
HBase并未将说明性查询语言作为核心实现的一部分，对事务的支持也有限，但行原子性和“读-修改-写”操作在实践中弥补了这个缺陷，它们覆盖了大部分的使用场景并消除了在其它系统中经历过的死锁，等待等问题。
HBase在进行负载均衡和故障恢复时对客户端是透明的，在生产系统中，系统的可扩展性体现在系统自动 伸缩的过程中，更改集群并不涉及重新全量负载均衡和数据重分区，但整个处理过程完全是自动化的。
</pre>

<pre>
下载安装
    下载HBase，解压，配置conf/hbase-site.xml， 配置数据目录， 启动， bin/start-hbase.sh, 进入 bin/hbase shell, status， 查询hbase运行状态
</pre>

<pre>
在实践中，为了能够像MapReduce一样有效的利用你HDFS, HBASE大多始于Hadoop安装在一起的，这样能够很大程度上减少对网络I/O的需求，同时能够加快处理速度，当在同一个服务器上运行Hadoop和HBase时，
最少会有三个进程((DataNode, TaskTracker, RegionServer)

服务器
    在HBase和Hadoop中有两种类型的机器:
	     Master（HDFS的NameNode, MapReduce的jobtracker, 以及HBase的Master）
		 Slave(HDFS的DataNode, MapReduce的tasktracker， 以及HBase的RegionServer)

CPU
   使用单核CPU机器，同时运行3个或者更多的Java进程和操作系统的服务进程是不合理的，在生产系统中，通常采用的是多核处理器。四核的处理器能够满足需求。
</pre>

![](https://i.imgur.com/t9rmxAX.jpg)

<pre>
磁盘
    数据存储在slave机器上，因此slave机器需要大量的存储空间，用户需要根据主要是面向读写，还是数据加工，来平衡可用的CPU内核数量与磁盘数量的使用。通常应该
	保证每个磁盘至少一个核，所以在8核心服务器增加6块磁盘是较优的，加入更多磁盘可能并不会带来显著的性能提升。
	磁盘模式： JBOD模式
	          RAID模式
	一般推荐使用SATA盘，因为SATA比SAS更节省成本，虽然SAS安全性比SATA高，但是一半的软件策略中是跨机架数据冗余，因此可以放心的使用SATA盘，虽然3.5英寸的磁盘比2.5英寸的磁盘可靠，但考虑到服务器机架的因素，可以选择2.5寸的磁盘。
</pre>

<pre>
Hadoop
    目前HBase只能依赖特定的Hadoop版本，其中的主要原因之一是HBase与Hadoop之间的远程调用API，RPC协议是版本华的，并且需要调用方与被调用方相互匹配，细微的差异就可能导致通信失败。
</pre>

<pre>
HBase是生产中使用最广泛的且进过检验的文件系统，几乎所有的生产集群都是用HDFS作为底层存储层，它被证明是稳定可靠的系统，然而不适用HDFS可能会产生不可控的风险和一些后续的问题。
HDFS如此受欢迎的主要原因是，它的机制包含了冗余，容错性和可扩展性。无论选择哪个文件系统都应该提供类似的保障，因为HBASE需要嘉定文件系统的数据存储是可靠度额，并且HBASE本身没有办法复制
数据并维护自身存储文件袋额副本，因此较低层次的文件系统必须提供此功能
</pre>

![](https://i.imgur.com/CmThJmL.jpg)

<pre>
本地模式
    本地文件系统实际上完全绕过了Hadoop，即不使用HDFS或任何其他集群，HBase使用FileSystem类连接到文件系统实现。
</pre>

<pre>
HDFS
   Hadoop分布式文件系统是默认的文件系统，它部署在一个完全分布式的集群中，Hbase选择HDFS作为文件系统，是因为HDFS具有所有必须的功能，如MapReduce的耦合，能够充分利用并行流式的处理能力，并且拥有较好的扩展性，系统可靠性和自动冗余功能，是理想的可靠的文件存储系统，HBASE增加了随机存取层，是HDFS缺失的部分，是对Hadoop的理想补充，另外利用MapReduce的并行能力可以执行批量导入数据的功能，最大限度利用磁盘带宽。
</pre>

<pre>
Hbase编译源码
   Hbase依赖Maven编译工程，因此用户需要安装Maven,以及JDK
Hbase运行
   单机模式，分布式模式
   conf/hbase_env.sh文件指定HBase的Java安装目录
   单机模式下：
      HBase并不适用HDFS，而是适用本地文件系统，
   分布式模式：
      伪分布式模式：所有守护进程都运行在同一个节点上
      完全分布式模式：进程运行在物理服务器集群中
   分布式模式依赖Hadoop分布式文件系统。
</pre>

<pre>
Zookeeper
   分布式的HBASE依赖与Zookeeper集群，所有的节点和客户端都必须能够正常访问Zookeeper，HBase默认管理一个单点的Zookeeper集群，用户通过启动和关闭脚本就可以把Zookeeper当做HBase的一部分来启动和关闭，，用户也可以不依赖HBASE管理Zookeeper集群，只需为HBase指出需要使用的集群即可，
</pre>

<pre>
HBase Master默认基于WEB的UI服务端口为60010,
</pre>

<pre>
PUT
每一个PUT操作实际上都是一个RPC操作，它将客户端数据传送到服务器然后返回，这只适合小数据量的操作，如果有个应用程序需要每秒存储上千行数据到HBASE表中，这样的处理就太不合适了。
    减少独立RPC调用的关键是限制往返时间，往返时间就是客户端发送一个请求到服务器，然后服务器通过网络进行响应的时间，这个时间不包含数据实际传输的时间，它其实就是通过线路传送网络包的开销，
    另外一个重要的因素是消息大小，如果通过网络发送的请求内容较大，那么需要请求返回的次数相应较少，这是因为时间主要花费在数据传递上，不过如果传递的数据量很小，比如一个计数器递增操作，那么用户把多次修改的数据批量提交给服务器并较少请求次数，性能会有相应提升。

HBASE的API配备了一个客户端的写缓冲区，缓冲区负责收集PUT操作，然后调用RPC操作一次性将PUT发送给服务器，全局交换机控制着该缓冲区是否在使用，

由于客户端缓冲区是一个简单的保存在客户端进程内存里的列表，用户需要注意不能再运行时终止程序，如果发生这种情况，那些尚未刷写的数据就会丢失，服务器将无法收到数据，因此这些数据没有任何副本可用来回复。
List<Put>

Get
Get get = new Get(row2);
get.addColumn()
Result[] result = table.get(get2)

Result
   当用户使用get()方法获取数据时，HBase返回的结果包含所有的匹配的单元格数据，这些数据将被封装在一个Result实例中返回给用户，

Delete
 Delete delete = new Delete();
 table.delete(delete)

行锁：
   像put(), delete(), checkAndPut()，这样的修改操作是独立运行的，这意味着在一个串行方式执行中，对于每一行必须保证行级别的操作是原子性的region服务器提供了一个行锁(row lock)的特性，这个特性保证了一个客户端能获取一行数据应用的锁，同时对该机制进行修改，在实践中，大部分客户端应用程序都没有提供显示的锁，而是适用这个机制来保障每个操作的独立性。

   用户应该尽可能的避免适用行锁，就像在RDBMS中，两个客户端很可能在拥有对方要请求的锁时，又同时请求对方持有的锁，这样便形成死锁j
 
   锁超时之前，两个被阻塞的客户端占用一个服务器端的处理线程，而这个线程时一种十分稀缺的资源，如果在一个频繁操作的行上发生了这种情况，那么很多其它的客户端会占用所有的处理线程，阻塞所有其他客户端访问这台服务器，导致这个region服务器将不能为其负责的region内的行提供服务。

   在不必要的情况下，尽量不要使用行锁，如果必须要使用，那么一定要节约占用锁的时间。

   当一个锁被服务器端或者客户端显式获取之后，其他所有想要对这行数据加锁的客户端将会等待，知道当前锁被释放，或者锁的租期超时，后者是了确保错误进程不会占用锁太长的时间或者无限期占用。(当前默认是1分钟)

   hbase_site.xml
   <property>
       <name> hbase.regionserver.lease.period</name>
       <value>120000</value>
   </property>

Scan
   扫描技术，这种技术类似于数据库系统中的游标，并利用到了HBASE提供的底层顺序存储的数据结构。

   扫描操作的使用跟get()方法非常相似。

   ResultScanner
       扫描操作不会通过一次RPC请求返回所有匹配的行，而是以行为单位进行返回，很明显，行的数目很大，可能有上千条甚至更多，同时在一次请求中发送大量数据，会占用大量的系统资源并消耗很长时间.
</pre> 