# HBaseTree
HBase 技术研究

![](https://i.imgur.com/XKgWQsD.png)

![](https://i.imgur.com/9JukYh2.jpg)

<pre>
列式存储数据库以列为单位聚合数据，然后将列值顺序的存入磁盘，这种存储方法不同于行式存储的传统数据库库，行式存储数据库连续的
存储整行。

列式存储的出现主要基于这样一种假设：对于特定的查询，不是所有的值都是必须的，尤其是在分析型数据库里，这种情况很常见。

在这种设计中，减少I/O只是众多主要因素之一，它还有其它的优点：
    因为列的数据类型天生是相似的，即便逻辑上每一行之间有轻微的不同，但仍旧比按行存储的结构聚集在一起的数据更利于压缩，因为大多数的压缩只关注有限的压缩窗口
</pre>

![](https://i.imgur.com/N4Q4UaC.jpg)

<pre>
一行由若干列组成，若干列又构成一个列族，一个列族的所有列存储在同一个底层的存储文件里，这个列族文件叫做HFile

列族需要在表创建时就定义好，并且不能修改得太频繁，数量也不能太多。

常见的引用列的格式为  family:qualifier，列族的数量最多只限于几十，实际更小，然而一个列族中的列的数量没有限制。

HBase是按照BigTable模型实现的，是一个稀疏的，分布式的，持久化的，多维的映射，由行键，列键，时间戳索引。

存储文件通常保存在hadoop分布式文件系统HDFS中，HDFS提供一个可扩展的，持久的，冗余的HBase存储层。存储文件通过将更改写入到可配置数目的物理服务器中，以保证数据不丢失。

每次更新数据时，都会先将数据记录在（commit log）提交日志中，在HBase中这叫做预写日志（write-ahead log, WAL），然后才会将这些数据写入内存中的
memstore中，一旦内存保存的写入数据的累积超过一个给定的最大值，系统就会将这些数据移出内存作为HFile文件刷写到磁盘中，数据移出内存之后，系统就会
丢弃对应的提交日志，只保留未持久化到磁盘中的提交日志，在系统将数据移出memstore写入磁盘的过程中，可以不必阻塞系统的读写，通过滚动内存中的memstore
就可以达到这个目的，即用空的新的memstore获取更新数据，将满的旧的memstore转换成一个文件。
</pre>

<pre>
HBase自动分区
    HBase中扩展和负载均衡的基本单元称为region，region本质上是以行键排序的连续存储的区间，如果region太大，系统就会把它们动态拆分，相反地，就把多个region合并，以减少存储文件数量。

HBase是一个分布式的，持久的，强一致性的存储系统，具有近似最优的写性能和出色的读性能，它充分利用了磁盘空间，支持特定列族切换可压缩算法。
HBase继承自BigTable模型，只考虑单一的索引，类似于RDBMS中的主键，提供了服务器端钩子，可以实施灵活的辅助索引解决方案，此外，它还提供了过滤器功能，减少了网络传输的数据量。
HBase并未将说明性查询语言作为核心实现的一部分，对事务的支持也有限，但行原子性和“读-修改-写”操作在实践中弥补了这个缺陷，它们覆盖了大部分的使用场景并消除了在其它系统中经历过的死锁，等待等问题。
HBase在进行负载均衡和故障恢复时对客户端是透明的，在生产系统中，系统的可扩展性体现在系统自动 伸缩的过程中，更改集群并不涉及重新全量负载均衡和数据重分区，但整个处理过程完全是自动化的。
</pre>

<pre>
下载安装
    下载HBase，解压，配置conf/hbase-site.xml， 配置数据目录， 启动， bin/start-hbase.sh, 进入 bin/hbase shell, status， 查询hbase运行状态
</pre>

<pre>
在实践中，为了能够像MapReduce一样有效的利用你HDFS, HBASE大多始于Hadoop安装在一起的，这样能够很大程度上减少对网络I/O的需求，同时能够加快处理速度，当在同一个服务器上运行Hadoop和HBase时，
最少会有三个进程((DataNode, TaskTracker, RegionServer)

服务器
    在HBase和Hadoop中有两种类型的机器:
	     Master（HDFS的NameNode, MapReduce的jobtracker, 以及HBase的Master）
		 Slave(HDFS的DataNode, MapReduce的tasktracker， 以及HBase的RegionServer)

CPU
   使用单核CPU机器，同时运行3个或者更多的Java进程和操作系统的服务进程是不合理的，在生产系统中，通常采用的是多核处理器。四核的处理器能够满足需求。
</pre>

![](https://i.imgur.com/t9rmxAX.jpg)

<pre>
磁盘
    数据存储在slave机器上，因此slave机器需要大量的存储空间，用户需要根据主要是面向读写，还是数据加工，来平衡可用的CPU内核数量与磁盘数量的使用。通常应该
	保证每个磁盘至少一个核，所以在8核心服务器增加6块磁盘是较优的，加入更多磁盘可能并不会带来显著的性能提升。
	磁盘模式： JBOD模式
	          RAID模式
	一般推荐使用SATA盘，因为SATA比SAS更节省成本，虽然SAS安全性比SATA高，但是一半的软件策略中是跨机架数据冗余，因此可以放心的使用SATA盘，虽然3.5英寸的磁盘比2.5英寸的磁盘可靠，但考虑到服务器机架的因素，可以选择2.5寸的磁盘。
</pre>

<pre>
Hadoop
    目前HBase只能依赖特定的Hadoop版本，其中的主要原因之一是HBase与Hadoop之间的远程调用API，RPC协议是版本华的，并且需要调用方与被调用方相互匹配，细微的差异就可能导致通信失败。
</pre>

<pre>
HBase是生产中使用最广泛的且进过检验的文件系统，几乎所有的生产集群都是用HDFS作为底层存储层，它被证明是稳定可靠的系统，然而不适用HDFS可能会产生不可控的风险和一些后续的问题。
HDFS如此受欢迎的主要原因是，它的机制包含了冗余，容错性和可扩展性。无论选择哪个文件系统都应该提供类似的保障，因为HBASE需要嘉定文件系统的数据存储是可靠度额，并且HBASE本身没有办法复制
数据并维护自身存储文件袋额副本，因此较低层次的文件系统必须提供此功能
</pre>

![](https://i.imgur.com/CmThJmL.jpg)

<pre>
本地模式
    本地文件系统实际上完全绕过了Hadoop，即不使用HDFS或任何其他集群，HBase使用FileSystem类连接到文件系统实现。
</pre>

<pre>
HDFS
   Hadoop分布式文件系统是默认的文件系统，它部署在一个完全分布式的集群中，Hbase选择HDFS作为文件系统，是因为HDFS具有所有必须的功能，如MapReduce的耦合，能够充分利用并行流式的处理能力，并且拥有较好的扩展性，系统可靠性和自动冗余功能，是理想的可靠的文件存储系统，HBASE增加了随机存取层，是HDFS缺失的部分，是对Hadoop的理想补充，另外利用MapReduce的并行能力可以执行批量导入数据的功能，最大限度利用磁盘带宽。
</pre>

<pre>
Hbase编译源码
   Hbase依赖Maven编译工程，因此用户需要安装Maven,以及JDK
Hbase运行
   单机模式，分布式模式
   conf/hbase_env.sh文件指定HBase的Java安装目录
   单机模式下：
      HBase并不适用HDFS，而是适用本地文件系统，
   分布式模式：
      伪分布式模式：所有守护进程都运行在同一个节点上
      完全分布式模式：进程运行在物理服务器集群中
   分布式模式依赖Hadoop分布式文件系统。
</pre>

<pre>
Zookeeper
   分布式的HBASE依赖与Zookeeper集群，所有的节点和客户端都必须能够正常访问Zookeeper，HBase默认管理一个单点的Zookeeper集群，用户通过启动和关闭脚本就可以把Zookeeper当做HBase的一部分来启动和关闭，，用户也可以不依赖HBASE管理Zookeeper集群，只需为HBase指出需要使用的集群即可，
</pre>

<pre>
HBase Master默认基于WEB的UI服务端口为60010,
</pre>

<pre>
PUT
每一个PUT操作实际上都是一个RPC操作，它将客户端数据传送到服务器然后返回，这只适合小数据量的操作，如果有个应用程序需要每秒存储上千行数据到HBASE表中，这样的处理就太不合适了。
    减少独立RPC调用的关键是限制往返时间，往返时间就是客户端发送一个请求到服务器，然后服务器通过网络进行响应的时间，这个时间不包含数据实际传输的时间，它其实就是通过线路传送网络包的开销，
    另外一个重要的因素是消息大小，如果通过网络发送的请求内容较大，那么需要请求返回的次数相应较少，这是因为时间主要花费在数据传递上，不过如果传递的数据量很小，比如一个计数器递增操作，那么用户把多次修改的数据批量提交给服务器并较少请求次数，性能会有相应提升。

HBASE的API配备了一个客户端的写缓冲区，缓冲区负责收集PUT操作，然后调用RPC操作一次性将PUT发送给服务器，全局交换机控制着该缓冲区是否在使用，

由于客户端缓冲区是一个简单的保存在客户端进程内存里的列表，用户需要注意不能再运行时终止程序，如果发生这种情况，那些尚未刷写的数据就会丢失，服务器将无法收到数据，因此这些数据没有任何副本可用来回复。
List<Put>

Get
Get get = new Get(row2);
get.addColumn()
Result[] result = table.get(get2)

Result
   当用户使用get()方法获取数据时，HBase返回的结果包含所有的匹配的单元格数据，这些数据将被封装在一个Result实例中返回给用户，

Delete
 Delete delete = new Delete();
 table.delete(delete)

行锁：
   像put(), delete(), checkAndPut()，这样的修改操作是独立运行的，这意味着在一个串行方式执行中，对于每一行必须保证行级别的操作是原子性的region服务器提供了一个行锁(row lock)的特性，这个特性保证了一个客户端能获取一行数据应用的锁，同时对该机制进行修改，在实践中，大部分客户端应用程序都没有提供显示的锁，而是适用这个机制来保障每个操作的独立性。

   用户应该尽可能的避免适用行锁，就像在RDBMS中，两个客户端很可能在拥有对方要请求的锁时，又同时请求对方持有的锁，这样便形成死锁j
 
   锁超时之前，两个被阻塞的客户端占用一个服务器端的处理线程，而这个线程时一种十分稀缺的资源，如果在一个频繁操作的行上发生了这种情况，那么很多其它的客户端会占用所有的处理线程，阻塞所有其他客户端访问这台服务器，导致这个region服务器将不能为其负责的region内的行提供服务。

   在不必要的情况下，尽量不要使用行锁，如果必须要使用，那么一定要节约占用锁的时间。

   当一个锁被服务器端或者客户端显式获取之后，其他所有想要对这行数据加锁的客户端将会等待，知道当前锁被释放，或者锁的租期超时，后者是了确保错误进程不会占用锁太长的时间或者无限期占用。(当前默认是1分钟)

   hbase_site.xml
   <property>
       <name> hbase.regionserver.lease.period</name>
       <value>120000</value>
   </property>

Scan
   扫描技术，这种技术类似于数据库系统中的游标，并利用到了HBASE提供的底层顺序存储的数据结构。

   扫描操作的使用跟get()方法非常相似。

   ResultScanner
       扫描操作不会通过一次RPC请求返回所有匹配的行，而是以行为单位进行返回，很明显，行的数目很大，可能有上千条甚至更多，同时在一次请求中发送大量数据，会占用大量的系统资源并消耗很长时间.

       缓存与批量处理
            到目前为止，每一个next()调用都会为每一行数据生成一个单独的RPC请求，即使使用next()方法，也是如此，因为该方法仅仅是在客户端循环调用next()方法，很显然，当单元格数据较小时，这样做的性能不会很好，因此如果一次RPC请求可以获取多行数据，这样会更有意义，这样的方法可以由扫描缓存（scanner caching）实现，
           
            hbase_site.xml中设置
            <property>
                 <name>hbase.client.scanner.caching</name>
                 <value>10</value>
            </property>

HTable的实用方法
      客户端API是HTable类的实例提供的，用户可以用它来操作HBASE表，除了之前提到过的一些主要特征外，还有如下值得注意的方法
      close()
      
Bytes类
      API和HBASE内部都把数据存储为一个较大的数组
      Bytes类支持以下原生JAVA类型字节数组的互转，String, boolean, short, int, long, double, float，
</pre> 

<pre>
过滤器
      HBASE过滤器（filter）提供了非常强大的特性来帮助用户提高其处理表中数据的效率，用户不仅可以使用HBASE预定义好的过滤器，而且可以实现自定义的过滤器

HBASE中主要的两种数据读取函数是get(), scan(), 它们都支持直接访问数据和通过指定起止行键访问数据的功能，读者可以再查询中添加更多的限制条件来减少查询得到的数据量，这些限制可以是指定列族，列，时间戳以及版本号，但是这些限制缺少一些细粒度的筛选功能，比如基于正则表达式对行键或值进行筛选.

所有的过滤器都在服务端生效，叫做谓词下推，这样可以保证被过滤掉的数据不会被传送到客户端。

比较器：CompareFilter 继承自Filter
行过滤器： RowFilter 基于行键来过滤数据
列族过滤器 FamilyFilter 基于列族比较
列名过滤器
值过滤器  ValueFilter
参考列过滤器器
专用过滤器
      1）单列值过滤器
      2）前缀过滤器
      3）分页过滤器   可以使用这个过滤器对结果进行分页
      5）列技术过滤器
      6）列分页过滤器
      7）列前缀过滤器
      8）随机行过滤器
</pre>

<pre>
计数器
     许多收集统计信息的应用有点击流或者在线广告意见，这些应用需要被收集到日志文件中用于后续的分析，用户可以使用计数器做实时统计，从而放弃延时较高的批量处理操作。

>incr 'counters', '20110101', 'daily:hits' 1
</pre>

<pre>
协处理器
     使用客户端API，配合筛选机制，例如，使用过滤器或限制列族的范围，都可以控制被返回客户端的数量，如果可以更进一步优化会更好，例如，数据的处理流程直接放到服务器端执行，然后返回一个小的处理结果集，这类似于一个小型的MapReduce框架，该框架将工作分发到整个集群。

     协处理器允许用户在region服务器上运行自己的代码，更准确的说是允许用户执行region级的操作，并且可以使用与RDMS中触发器类似的功能，在客户端，用户不用关心操作具体在哪里执行，HBASE的分布式框架会帮助用户把这些工作变得透明。

     协处理器可以动态加载，这一些可以使得用户在HBASE集群运行中扩展其功能。

     协处理器框架已经提供了一些类，用户可以通过集成这些类来扩展自己的功能，这些类主要分为两大类， observer：与触发器类似，回调函数在一些时间发生时被执行。
             endpoint：除了时间处理之外还需要将用户自定义操作添加到服务端，用户代码可以被部署到管理数据的服务器端，

     Coprocessor类
             所有协处理器都必须实现这个接口，它定义了协处理器的基本约定，并使得框架本省的管理变得容易。
</pre>

<pre>
HTablePool
    与其为客户端的每个请求创建一个HTable实例，不如创建一个实例，然后不断的服用这个实例。
    按以上方式操作的主要原因，是创建HTable实例是一项非常耗时的操作，通常耗时数秒，才能完成，在资源高度紧张的环境中，每秒都有几千个请求，为每个请求单独创建HTABLE实例根本行不通，这种方式速度太慢了以至于无法调用方法，用户应该在一开始创建实例，然后再哎客户端生命周期内不断的复用他们。

    但是在多线程环境下重用HTABLE实例会出现其他问题。
          HTABLE类不是线程安全的，本地的写缓冲区并不能保证一致性，即使使用SetAutoFlush也无济于事，你必须为每个线程创建一个HTABLE实例。
 
    客户端可以通过HTABLEPOOL类来解决这个问题，它只有一个目的，那就是为HBASE集群提供客户端连接池
          getTable()获取HTABLE实例
          putTable()将实例放回
</pre>

<pre>
连接管理
     每个HTable实例都需要建立和远程主机的连接。这些连接在内部使用HConnection类标识，

     HBASE内部使用键值映射来存储连接，使用Configuration实例作为键值映射的键，换句话说，当你创建很多HTable实例时，如果你提供了Configuration的引用，那么他们都共享一个底层的HConnection实例。

     共享Zookeeper连接
          因为每个客户端最终都需要Zookeeper连接来完成表的region地址初始寻址，连接一旦建立，共享就变得很有意义，这时候之后的客户端实例可以共用

     缓存通用资源
          通过zookeeper查询到的-ROOT 和.META的地址，以及region的地址定位都需要网络传输开销，这些地址将被缓存在客户端来减少网络的调用次数，因此达到加速寻址的目的。

          对于每个连接到远程集群的本地客户端来说，他们的地址表都是相同的，因此运行相同进程的客户端共享连接非常有用，这是通过共享HConnection实例来实现的，里另外，当寻址失败时，连接有内置的重试机制来刷新缓存，对于其他所有共享相同连接引用的客户端来说，这些更改立即生效，因此这更加减少了客户端初始化连接的开销。

          另一个受益的类是HTablePOOL,所有连接池中的HTABLE实例都自动共用一个提供的Configuration实例，因此他们也共享连接，因为当用户想创建多个HTABLE实例时，最好先创建一个共用的Configuration实例。

          共享连接的缺点
                如果用户不显式关闭连接，它将一直存在，知道客户端退出，这样可能导致很多Zookeeper连接都保持打开状态，尤其是在大型分布式环境下，比如执行MapReduce作业的HBASE程序，这样可能会产生一些问题，最坏的情况下是耗尽所有的连接句柄，并导致I/O异常。
                用户可以通过显式关闭连接来避免这种情况，建议用户不再需要HTABLE时，主动调用HTABLE的close方法，调用这个方法将释放所有的共享资源，其中包括Zookeeper连接，
</pre>

![](https://i.imgur.com/SSZzsNi.jpg)

<pre>
表
    在HBASE中数据最终会存储在一张表或多张表中，使用表的主要原因是控制表中的所有列以达到共享表内的某些特性的目的。一个典型的例子是定义表的列族。
    HTableDescirptor
    Api提供的大多数类都拥有一个特殊的构造函数，即一个不带任何参数的构造函数，因为这些类都实现了Hadoop Writable接口， 客户端与服务端进行内部通信，都是用到了Hadoop RPC框架，这个框架中需要远程方法中的参数都实现Writable接口，进而能够序列化对象并进行远程传输，Writable接口有两个必须实现的方法
          write(), readFile()
          框架通过调用这两个方法把对象序列化成输出流，通信接收端读取字节流，并将其反序列化成对象。

    HBASE列式存储格式允许用户存储大量的信息到相同的表中，而在RDBMS模型中，大量的信息则需要切分成多张表存储，通常的数据库范式化规则不适合HBASE，因此在HBASE中表的数量相对较少。。

    理论上HBASE的表由行和列组成的，但是从屋里结构上看，表存储在不同的分区，即不同的region，每个region只在一个region服务器中提供服务，而region直接向客户端提供存储服务。

    当region的大小达到配置的大小时，文件大小限制会帮助HBASE拆分region，默认一个Region的大小为256MB，用户可按照实际情况自己调整。
    
    定位列族中某个具体的列
         family:qualifier

    HBaseAdmin类
         1)HBaseAdmin提供了建表，创建列族，检查表是否存在，修改表结构和列族结构和删除表等功能
         createTable
         2)集群管理操作，允许用户查看集群当前的状态，执行表任务和管理region 
</pre>

<pre>
每个请求使用一个服务而非建立一个新连接的优势--用户需要服用连接来获取最优性能，生存期短的进程将在建立连接以及准备元数据上话费更多的时间，而非在其实际操作上花费时间，尤其是服务器端缓存这region的位置信息，这使得复用非常重要，否则每个客户端都将进行一次完成的从行到region的逐字节的查找来获取他们想要的信息。

在高吞吐量场景中，纯二进制格式的thrift具有更大的优势，
如果用户仅有少许的请求，但是数据量比较大，那么REST的场景更合适

REST场景
    REST支持现有的基于WEB的体系，它能够完美的融合反向代理和其他缓存技术，并行运行许多REST服务可以分摊他们之间的负载，
Thrift/Avro场景
    当用户从吞吐量的角度考虑需要的最佳性能时，可以使用严禁的二级制协议，用户可以运行较少的服务，

MapReduce
    大多数处理批量读写HBASE的框架是基于MapReduce的模式
    Hadoop MapReduce框架爱的目标是处理PB级的数据，具有高可用，目标明确，编程模型简单易用等特点，
    Hive 基于Hadoop的数据仓库，提供了类似SQL的处理语言，叫HiveQL， 允许用户查询存储在  Hadoop中的半截话数据
    Pig 分析海量数据的平台
    Cascading是MapReduce的替代API，实际上它使用MapReduce执行作业，但用户在开发时不必以MapReduce的模式来考虑它的执行。
    HBase Shell是HBase集群的命令行接口，用户可以使用Shell访问本地或者远程服务器并与其进行交互，Shell同时提供了客户端和管理功能的操作

WEB-UI
</pre>

<pre>
与MapReduce集成
    HBase最大的特点之一就是可以紧密的与Hadoop的MapReduce框架集成

    MapReduce被设计为可以再可扩展的方式下解决超过TB级数据处理过程中的问题。应当有一种方法可以建立一个性能随机器数增加而线性提升的系统，这就是MapReduce努力做到的，它遵守分而治之原则，通过将数据迟爱芬到分布式文件系统中的不同机器上，让服务器能尽快直接访问和处理数据，这种方法的问题是用户最终需要合并全局结构，同样，MapReduce为解决这个问题将其内置了。
</pre>